{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Adaptive QARM Demo â€“ SciBERT QA Relationship Classifier\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Loading a fine-tuned SciBERT model\n",
    "- Running inference on QA pairs\n",
    "- Computing Integrated Gradients for interpretability\n",
    "- Visualizing token attributions\n",
    "\n",
    "Developed for REFSQ 2025 Research Prototype."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from integrated_gradients import IntegratedGradientsExplainer\n",
    "from utils import qa_to_text\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "MODEL_PATH = 'allenai/scibert_scivocab_uncased'  # Replace with fine-tuned path if available\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=3)\n",
    "explainer = IntegratedGradientsExplainer(tokenizer, model, device='cpu')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Inference"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "example_text = qa_to_text('Security', 'Performance')\n",
    "inputs = tokenizer(example_text, return_tensors='pt')\n",
    "outputs = model(**inputs)\n",
    "probs = torch.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "labels = ['Support', 'Conflict', 'Neutral']\n",
    "pred_label = labels[torch.argmax(probs)]\n",
    "print(f\"QA Pair: {example_text}\\nPredicted Relation: {pred_label}\\nConfidence: {probs.max().item():.3f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients Attribution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result = explainer.attribute(example_text, target=1)  # Conflict class index\n",
    "tokens = result['tokens']\n",
    "scores = np.array(result['normalized'])\n",
    "\n",
    "plt.figure(figsize=(10, 0.5))\n",
    "colors = plt.cm.RdYlGn((scores - scores.min()) / (scores.max() - scores.min()))\n",
    "plt.bar(range(len(tokens)), scores, color=colors)\n",
    "plt.xticks(range(len(tokens)), tokens, rotation=90)\n",
    "plt.title('Token Attribution (Integrated Gradients)')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
